<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Mohamed Afham</title>
  
  <meta name="author" content="Mohamed Afham">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <style>
    #myimg{
      width:100%;
      max-width:100%;
      border-radius:50%;
      border: 1px solid #ddd;
  padding: 5px;
    }

    p {
      line-height: 22px;
      font-size: 15px;
    }

    ul li{
     font-size:15px;
    }
    
  </style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <!-- <p style="text-align:center"> -->
                <!-- <name>Mohamed Afham</name> -->
                <p id="namechange" align="center">
                  <span id="a"><name>Mohamed Afham</name></span> <!--<span id="b" style="font-family: 'Gugi', cursive; font-size: 40px;">अक्षिता गुप्ता </span>-->
              </p>
              <p style="text-align:justify" >
                I am a final year undergraduate at <a href="https://ent.uom.lk">Department of Electronics and Telecommunication Engineering, University of Moratuwa, Sri Lanka</a>. 
                Currently I'm working on my bachelor's thesis on Learning Representations for 3D Point Cloud Processing, advised by <a href="https://ranga.staff.uom.lk">Dr. Ranga Rodrigo</a>
                and <a href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/kanchana-thilakarathna.html">Dr. Kanchana Thilakarathna</a>.
                I gained industry experience working as an Associate Machine Learning Engineer at <a href="https://veracityai.com/en/">VeracityAI</a> in collaboration with <a href="https://wenn.no">WENN</a>, 
                analyzing the SOTA object detection algorithms for an effective car damage detection. 
              </p>
              <p style="text-align:justify" > 
                I'm interested in Computer Vision and Machine Learning with focus on the subdomains of <strong>self-supervised learning, contrastive learning, multi-modal learning and learning with limited labels (few-shot, zero-shot).</strong>
                I completed my research internship under the supervision of <a href="https://salman-h-khan.github.io">Dr. Salman Khan</a> at <a href="https://mbzuai.ac.ae"> MBZUAI, UAE</a>. 
              </p>
              <p style="text-align:center">
                <a href="mailto:afhamaflal9@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://MohamedAfham.github.io/Resume/Afham_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=xGuhVGAAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/MohamedAfham14">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/MohamedAfham">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/DP.jpg"><img id = "myimg" alt="profile photo" src="images/DP.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                <strong>[Jan 2022]</strong> &nbsp;&nbsp;One paper accepted at ICASSP 2022.<br />
                <strong>[Nov 2021]</strong> &nbsp;&nbsp;Serving as a reviewer for CVPR 2022.<br />
                <strong>[Oct 2021]</strong> &nbsp;&nbsp;One paper accepted at BMVC 2021.<br />
                <strong>[Oct 2021]</strong> <a href="https://arxiv.org/abs/2110.03578"> &nbsp;&nbsp;&nbsp;Towards Accurate Cross-Domain In-Bed Human Pose Estimation</a>: preprint available on arxiv. <br />
                <strong>[Sep 2021]</strong> &nbsp;&nbsp;&nbsp;Our team NFP Undercover emerged 2nd runners up at <a href="https://www.2021.ieeeicip.org/VIPCup.asp">IEEE VIP Cup.</a> <br />
                <strong>[Jun 2021]</strong> &nbsp;&nbsp;&nbsp;Joined <a href="https://veracityai.com/en/">VeracityAI</a> as an Associate Machine Learning Engineer. <br />
                <strong>[Apr 2021]</strong> <a href="https://arxiv.org/abs/2104.12709"> &nbsp;&nbsp;&nbsp;Rich Semantics Improve Few-Shot Learning</a>: preprint available on arxiv. <br />
                <strong>[Nov 2020]</strong> &nbsp;&nbsp;Our team Wanderers emerged as IEEE SMC winners of the BR41N.io hackathon.<br />
                <strong>[Oct 2020]</strong> &nbsp;&nbsp;Joined <a href="https://mbzuai.ac.ae">MBZUAI</a> as a Research Assistant.<br />
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="width:100%;vertical-align:middle">
            <heading>Research</heading>
            <p>
              I'm fascinated by the growth of computer vision community towards making the models see and understand the world as humans do. 
              In particular, I'm intrigued by the results of the models learnt with self-supervision or with label constrained environments. 
            </p>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/CrossPoint_Architecture.pdf' width="160">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding</papertitle>
            <br>
            <strong>Mohamed Afham</strong>,
            Isuru Dissanayake,
            Dinithi Dissanayake,
            Amaya Dharmasiri,
            Kanchana Thilakarathna,
            Ranga Rodrigo<br>
            <br>
            <em>Under Review</em>, 2021  
            <br>
            <a href="https://drive.google.com/file/d/1T4EX_lBW2symNe1bZwt2wEK4rzsNbyj5/view?usp=sharing">paper</a> /
            <a href="https://github.com/MohamedAfham/CrossPoint">code</a>
            <ul>
              <li>
                <u>Description:</u> Introduced a joint learning objective encapsulating intra-modal correspondence within point cloud modality
                and cross-modal correspondence between point cloud and 2D image modalities, leveraging contrastive learning.
              </li>
              <li>
                <u>Outcome:</u> Produced state-of-the-art performance in downstream tasks such as 3D object classification, few-shot object classification
                and 3D object part segmentation, outperforming previous unsupervised learning methods.

              </li>
            </ul>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/CD_HPE_Architecture.pdf' width="160">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>Towards Accurate Cross-Domain In-Bed Human Pose Estimation</papertitle>
            <br>
            <strong>Mohamed Afham<sup>*</sup></strong>,
            Udith Haputhanthri<sup>*</sup>,
            Jathurshan Pradeepkumar<sup>*</sup>,
            Mithunjha Anandakumar,
            Ashwin De Silva,
            Chamira Edussooriya<br>
            (* denotes equal contribution)
            <br>
            <strong>Accepted at ICASSP, 2022</strong> 
            <br>
            <a href="https://arxiv.org/abs/2110.03578">paper</a> /
            <a href="https://github.com/MohamedAfham/CD_HPE">code</a>
            <ul>
              <li>
                <u>Description:</u> Proposed a novel learning strategy with two-fold data augmentation and self-supervised knowledge distillation to reduce the domain discrepancy between labeled source domain and unlabeled target domain.
              </li>
              <li>
                <u>Outcome:</u> Improved performance on SLP dataset over two standard pose estimation baselines.
              </li>
            </ul>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/RS_FSL_Architecture.pdf' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Rich Semantics Improve Few-Shot Learning</papertitle>
              <br>
              <strong>Mohamed Afham</strong>,
              Salman Khan,
              Muhammad Haris Khan,
              Muzammal Naseer,
              Fahad Shahbaz Khan
              <br>
              <strong>BMVC, 2021</strong>  
              <br>
              <a href="https://arxiv.org/abs/2104.12709">paper</a> /
              <a href="https://github.com/MohamedAfham/RS_FSL">code</a>
              <ul>
                <li>
                  <u>Description:</u> Proposed a multi-modal architecture for few-shot learning  which leverages the class-level descriptions to learn better representations.
                </li>
                <li>
                  <u>Outcome:</u> Improved state-of-the-art performances on CUB, VGG-Flowers and ShapeWorld and competitive performance on miniImagenet.
                </li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td width="100%" valign="middle">
              <heading>Experience</heading>
            </td>
          </tr>
        </table>
        <table border="0" cellpadding="0" cellspacing="4">

          <tbody><tr><td valign="top" rowspan="6"><img height="46" border="0" src="images/veracityai_logo.png">
      
          </td></tr><tr><td></td><td></td><td></td><td></td><td></td><td valign="top" colspan="2"><span class="h1"><b>VeracityAI, Colombo, Sri Lanka</b></span>
        
          <br><em>Associate Machine Learning Engineer</em><br> 
          June 2021 - Feb 2022</a>
          
        </td></tr></tbody></table>
        <table border="0" cellpadding="0" cellspacing="4">

          <tbody><tr><td valign="top" rowspan="6"><img height="52" border="0" src="images/mbzuai_logo.png">
      
          </td></tr><tr><td></td><td></td><td></td><td></td><td></td><td valign="top" colspan="2"><span class="h1"><b>Mohamed Bin Zayed University of Artificial Intelligence, Abu Dhabi, UAE</b></span>
        
          <br><em>Research Assistant</em><br> 
          Oct 2020 - Apr 2021<br>
          Supervisor: Dr Salman Khan</a>
          
        </td></tr></tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td width="100%" valign="middle">
              <heading>Education</heading>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/uom_logo.jpg' width="150">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>University of Moratuwa, Sri Lanka </papertitle>
              <br>
              <em>Bachelor's in Science (Engineering) specialized in Electronics and Telecommunication</em>
              <br>
              <em>Aug 2017 - present</em>
              <br>
            </td>
          </tr>
        </tbody></table>
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
            <br>
            <p align="right">
              <font size="2">
              <strong>I borrowed this website layout from <a target="_blank" href="https://jonbarron.info/">here</a>!</strong>
          </font>
            </p>
            </td>
          </tr>
          </table>
      </td>
    </tr>
  </table>
</body>

</html>
